# å¤§æ¨¡å‹ç”ŸæˆTokençš„æ–¹å¼

> ä»£ç å·²æ›´æ–°åˆ° Happy-LLM ä»“åº“ç¬¬äº”ç« çš„ä»£ç ä¸­ã€‚

## è´ªå©ªè§£ç ï¼ˆGreedy Decodingï¼‰

### åŸç†è¯´æ˜
è´ªå©ªè§£ç æ˜¯æœ€ç®€å•ç›´æ¥çš„æ–‡æœ¬ç”Ÿæˆç­–ç•¥ã€‚åœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ï¼Œå®ƒæ€»æ˜¯é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„é‚£ä¸ªtokenä½œä¸ºä¸‹ä¸€ä¸ªtokenï¼Œç„¶åç»§ç»­ç”Ÿæˆï¼Œç›´åˆ°é‡åˆ°åœæ­¢æ¡ä»¶æˆ–è¾¾åˆ°æœ€å¤§é•¿åº¦ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šå±€éƒ¨æœ€ä¼˜é€‰æ‹© â†’ å¸Œæœ›å…¨å±€æœ€ä¼˜

**æ•°å­¦è¡¨è¾¾**ï¼š
```
token_t = argmax P(token_t | token_1, token_2, ..., token_{t-1})
```

### ä»£ç å®ç°
åŸºäºæˆ‘ä»¬å®ç°çš„ `_greedy_decode` æ–¹æ³•ï¼š

```python
def _greedy_decode(self, logits: torch.Tensor) -> torch.Tensor:
    """
    è´ªå©ªè§£ç ï¼šé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„token

    Args:
        logits: æ¨¡å‹è¾“å‡ºçš„logitsï¼Œå½¢çŠ¶ä¸º (batch_size, vocab_size)

    Returns:
        é€‰æ‹©çš„tokenç´¢å¼•ï¼Œå½¢çŠ¶ä¸º (batch_size, 1)
    """
    _, idx_next = torch.topk(logits, k=1, dim=-1)
    return idx_next
```

**å…³é”®æ­¥éª¤è§£æ**ï¼š
1. `torch.topk(logits, k=1, dim=-1)`ï¼šæ‰¾åˆ°logitsä¸­æœ€å¤§å€¼çš„ä½ç½®
2. è¿”å›æœ€å¤§æ¦‚ç‡tokençš„ç´¢å¼•
3. è¯¥tokenè¢«æ·»åŠ åˆ°åºåˆ—ä¸­ï¼Œç»§ç»­ä¸‹ä¸€è½®ç”Ÿæˆ

### ä½¿ç”¨ç¤ºä¾‹
```python
# åœ¨ generate_super å‡½æ•°ä¸­è°ƒç”¨è´ªå©ªè§£ç 
output = model.generate_super(
    input_ids,
    do_sample=False,      # ä¸ä½¿ç”¨é‡‡æ ·
    num_beams=1,          # ä¸ä½¿ç”¨æŸæœç´¢
    temperature=0.0,      # æ¸©åº¦ä¸º0ç¡®ä¿ç¡®å®šæ€§
    max_new_tokens=100
)
```

### ä¼˜ç¼ºç‚¹åˆ†æ

**ä¼˜ç‚¹**ï¼š
- âœ… **é€Ÿåº¦å¿«**ï¼šæ¯æ­¥åªéœ€è¦ä¸€æ¬¡å‰å‘ä¼ æ’­å’Œç®€å•çš„argmaxæ“ä½œ
- âœ… **ç»“æœç¡®å®š**ï¼šç›¸åŒçš„è¾“å…¥æ€»æ˜¯äº§ç”Ÿç›¸åŒçš„è¾“å‡º
- âœ… **å†…å­˜æ•ˆç‡é«˜**ï¼šä¸éœ€è¦ç»´æŠ¤å¤šä¸ªå€™é€‰åºåˆ—
- âœ… **å®ç°ç®€å•**ï¼šç®—æ³•é€»è¾‘ç›´è§‚æ˜“æ‡‚

**ç¼ºç‚¹**ï¼š
- âŒ **å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜**ï¼šæ¯æ­¥çš„å±€éƒ¨æœ€ä¼˜ä¸ä¸€å®šç­‰äºå…¨å±€æœ€ä¼˜
- âŒ **ç¼ºä¹å¤šæ ·æ€§**ï¼šæ€»æ˜¯äº§ç”Ÿç›¸åŒçš„åºåˆ—ï¼Œç¼ºä¹åˆ›é€ æ€§
- âŒ **å¯èƒ½äº§ç”Ÿé‡å¤å†…å®¹**ï¼šå®¹æ˜“é™·å…¥é‡å¤å¾ªç¯
- âŒ **å¿½ç•¥é•¿ç¨‹ä¾èµ–**ï¼šä¸è€ƒè™‘åºåˆ—çš„æ•´ä½“è¿è´¯æ€§

### å…¸å‹ä¾‹å­
å‡è®¾æ¨¡å‹ç”Ÿæˆäº†ä»¥ä¸‹æ¦‚ç‡åˆ†å¸ƒï¼š

```
è¾“å…¥: "ä»Šå¤©å¤©æ°”"
ä¸‹ä¸€tokenæ¦‚ç‡:
- "å¾ˆ" (0.4)
- "ä¸é”™" (0.3)
- "çœŸå¥½" (0.2)
- "ä¸å¤ªå¥½" (0.1)
```

è´ªå©ªè§£ç ä¼šé€‰æ‹©"å¾ˆ"ï¼Œç”Ÿæˆ"ä»Šå¤©å¤©æ°”å¾ˆ"ï¼Œç„¶åç»§ç»­è¿™ä¸ªè¿‡ç¨‹ã€‚

### ä½¿ç”¨åœºæ™¯
- **ç¡®å®šæ€§ä»»åŠ¡**ï¼šå¦‚æ•°å­¦è®¡ç®—ã€ä»£ç ç”Ÿæˆ
- **éœ€è¦ä¸€è‡´æ€§çš„åº”ç”¨**ï¼šå¦‚APIæœåŠ¡ã€è‡ªåŠ¨åŒ–è„šæœ¬
- **è®¡ç®—èµ„æºå—é™çš„ç¯å¢ƒ**ï¼šéœ€è¦å¿«é€Ÿç”Ÿæˆç»“æœ
- **åŸºå‡†æµ‹è¯•**ï¼šä½œä¸ºå…¶ä»–ç®—æ³•çš„å¯¹æ¯”åŸºå‡†

## é‡‡æ ·è§£ç ï¼ˆSampling Decodingï¼‰

### åŸç†è¯´æ˜
é‡‡æ ·è§£ç ä¸æ˜¯é€‰æ‹©æ¦‚ç‡æœ€å¤§çš„tokenï¼Œè€Œæ˜¯åŸºäºæ¨¡å‹çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œéšæœºé‡‡æ ·ã€‚è¿™æ ·å¯ä»¥åœ¨æ¯æ¬¡ç”Ÿæˆæ—¶äº§ç”Ÿä¸åŒçš„ç»“æœï¼Œå¢åŠ æ–‡æœ¬çš„å¤šæ ·æ€§å’Œåˆ›é€ æ€§ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šåŸºäºæ¦‚ç‡åˆ†å¸ƒéšæœºé€‰æ‹© â†’ å¢åŠ å¤šæ ·æ€§

**æ•°å­¦è¡¨è¾¾**ï¼š

```
token_t ~ P(token_t | token_1, token_2, ..., token_{t-1})
```

### å…³é”®å‚æ•°

#### 1. Temperatureï¼ˆæ¸©åº¦ï¼‰
- **ä½œç”¨**ï¼šæ§åˆ¶æ¦‚ç‡åˆ†å¸ƒçš„å¹³æ»‘ç¨‹åº¦
- **åŸç†**ï¼šå°†logitsé™¤ä»¥temperatureï¼Œç„¶åè¿›è¡Œsoftmax
- **æ•ˆæœ**ï¼š
  - `temperature > 1`ï¼šåˆ†å¸ƒæ›´å¹³æ»‘ï¼Œå¢åŠ éšæœºæ€§
  - `temperature < 1`ï¼šåˆ†å¸ƒæ›´å°–é”ï¼Œæ›´æ¥è¿‘è´ªå©ªè§£ç 
  - `temperature â†’ 0`ï¼šç­‰ä»·äºè´ªå©ªè§£ç 

#### 2. Top-k Sampling
- **ä½œç”¨**ï¼šé™åˆ¶å€™é€‰tokençš„èŒƒå›´
- **åŸç†**ï¼šåªè€ƒè™‘æ¦‚ç‡æœ€é«˜çš„kä¸ªtokenï¼Œå…¶ä»–tokenæ¦‚ç‡è®¾ä¸º0
- **æ•ˆæœ**ï¼šé¿å…é€‰æ‹©æ¦‚ç‡å¾ˆä½çš„"å¥‡æ€ª"tokenï¼Œæé«˜è´¨é‡

### ä»£ç å®ç°
åŸºäºæˆ‘ä»¬å®ç°çš„ `_random_sample` æ–¹æ³•ï¼š

```python
def _random_sample(self, logits: torch.Tensor, temperature: float = 1.0, top_k: int = None) -> torch.Tensor:
    """
    éšæœºé‡‡æ ·ï¼šåŸºäºæ¦‚ç‡åˆ†å¸ƒéšæœºé€‰æ‹©token

    Args:
        logits: æ¨¡å‹è¾“å‡ºçš„logitsï¼Œå½¢çŠ¶ä¸º (batch_size, vocab_size)
        temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶éšæœºæ€§
        top_k: åªè€ƒè™‘æ¦‚ç‡æœ€é«˜çš„kä¸ªtoken

    Returns:
        é€‰æ‹©çš„tokenç´¢å¼•ï¼Œå½¢çŠ¶ä¸º (batch_size, 1)
    """
    # 1. æ¸©åº¦ç¼©æ”¾
    logits = logits / temperature

    # 2. Top-kè¿‡æ»¤
    if top_k is not None:
        v, _ = torch.topk(logits, min(top_k, logits.size(-1)))
        logits[logits < v[:, [-1]]] = -float('Inf')

    # 3. è®¡ç®—æ¦‚ç‡å¹¶é‡‡æ ·
    probs = F.softmax(logits, dim=-1)
    idx_next = torch.multinomial(probs, num_samples=1)
    return idx_next
```

**å…³é”®æ­¥éª¤è§£æ**ï¼š
1. **æ¸©åº¦ç¼©æ”¾**ï¼šè°ƒæ•´æ¦‚ç‡åˆ†å¸ƒçš„å¹³æ»‘ç¨‹åº¦
2. **Top-kè¿‡æ»¤**ï¼šç§»é™¤ä½æ¦‚ç‡å€™é€‰ï¼Œæé«˜è´¨é‡
3. **æ¦‚ç‡å½’ä¸€åŒ–**ï¼šä½¿ç”¨softmaxå¾—åˆ°æ¦‚ç‡åˆ†å¸ƒ
4. **éšæœºé‡‡æ ·**ï¼šæ ¹æ®æ¦‚ç‡åˆ†å¸ƒéšæœºé€‰æ‹©token

### ä½¿ç”¨ç¤ºä¾‹
```python
# åŸºæœ¬é‡‡æ ·
output = model.generate_super(
    input_ids,
    do_sample=True,         # å¯ç”¨é‡‡æ ·
    num_beams=1,           # ä¸ä½¿ç”¨æŸæœç´¢
    temperature=0.8,       # ä¸­ç­‰æ¸©åº¦
    max_new_tokens=100
)

# å¸¦top-kçš„é‡‡æ ·
output = model.generate_super(
    input_ids,
    do_sample=True,
    num_beams=1,
    temperature=1.0,       # è¾ƒé«˜æ¸©åº¦å¢åŠ éšæœºæ€§
    top_k=50,             # åªè€ƒè™‘å‰50ä¸ªå€™é€‰
    max_new_tokens=100
)
```

### æ¸©åº¦å‚æ•°è¯¦è§£

**ä¸åŒæ¸©åº¦çš„æ•ˆæœå¯¹æ¯”**ï¼š

```python
# ç¤ºä¾‹æ¦‚ç‡åˆ†å¸ƒ
original_probs = [0.6, 0.2, 0.1, 0.05, 0.05]

# Temperature = 0.1 (ä½æ¸©åº¦ï¼Œæ¥è¿‘è´ªå©ª)
scaled_probs = [0.85, 0.08, 0.04, 0.015, 0.015]
# ç»“æœï¼šå¾ˆå¯èƒ½é€‰æ‹©ç¬¬ä¸€ä¸ªtoken

# Temperature = 1.0 (æ ‡å‡†æ¸©åº¦)
scaled_probs = [0.6, 0.2, 0.1, 0.05, 0.05]
# ç»“æœï¼šæŒ‰åŸå§‹æ¦‚ç‡é‡‡æ ·

# Temperature = 2.0 (é«˜æ¸©åº¦ï¼Œå¢åŠ éšæœºæ€§)
scaled_probs = [0.35, 0.25, 0.18, 0.11, 0.11]
# ç»“æœï¼šå„ä¸ªtokenéƒ½æœ‰æœºä¼šè¢«é€‰ä¸­
```

### Top-kæœºåˆ¶è¯¦è§£

**Top-kè¿‡æ»¤è¿‡ç¨‹**ï¼š

```python
# å‡è®¾è¯æ±‡è¡¨å¤§å°ä¸º1000ï¼Œtop_k=50
logits = [0.1, 2.3, 0.5, 1.8, 0.3, 3.2, 0.9, 0.2, 1.5, 0.7, ...]  # 1000ä¸ªå€¼

# æ­¥éª¤1ï¼šæ‰¾åˆ°å‰50ä¸ªæœ€å¤§å€¼
v, _ = torch.topk(logits, 50)
threshold = v[-1]  # ç¬¬50å¤§çš„å€¼

# æ­¥éª¤2ï¼šè¿‡æ»¤
logits[logits < threshold] = -float('Inf')
# ç»“æœï¼šåªæœ‰50ä¸ªtokenæœ‰éé›¶æ¦‚ç‡ï¼Œå…¶ä»–950ä¸ªtokenæ¦‚ç‡ä¸º0
```

### ä¼˜ç¼ºç‚¹åˆ†æ

**ä¼˜ç‚¹**ï¼š
- âœ… **å¤šæ ·æ€§å¥½**ï¼šæ¯æ¬¡ç”Ÿæˆå¯èƒ½äº§ç”Ÿä¸åŒçš„ç»“æœ
- âœ… **åˆ›é€ æ€§é«˜**ï¼šèƒ½äº§ç”Ÿæ„æƒ³ä¸åˆ°çš„å†…å®¹
- âœ… **é¿å…é‡å¤**ï¼šä¸å®¹æ˜“é™·å…¥é‡å¤å¾ªç¯
- âœ… **å¯è°ƒæ€§å¼º**ï¼šé€šè¿‡å‚æ•°æ§åˆ¶éšæœºç¨‹åº¦

**ç¼ºç‚¹**ï¼š
- âŒ **ç»“æœä¸ç¡®å®š**ï¼šç›¸åŒè¾“å…¥å¯èƒ½äº§ç”Ÿä¸åŒè¾“å‡º
- âŒ **è´¨é‡ä¸ç¨³å®š**ï¼šå¯èƒ½äº§ç”Ÿä½è´¨é‡æˆ–ä¸è¿è´¯çš„å†…å®¹
- âŒ **éœ€è¦è°ƒå‚**ï¼štemperatureå’Œtop_kéœ€è¦ä»”ç»†è°ƒèŠ‚
- âŒ **è®¡ç®—å¼€é”€**ï¼šéœ€è¦è®¡ç®—å®Œæ•´çš„æ¦‚ç‡åˆ†å¸ƒ

### ä½¿ç”¨åœºæ™¯
- **åˆ›æ„å†™ä½œ**ï¼šæ•…äº‹ç”Ÿæˆã€è¯—æ­Œåˆ›ä½œ
- **å¯¹è¯ç³»ç»Ÿ**ï¼šè®©å¯¹è¯æ›´åŠ è‡ªç„¶å’Œæœ‰è¶£
- **æ•°æ®å¢å¼º**ï¼šç”Ÿæˆå¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®
- **æ¢ç´¢æ€§ä»»åŠ¡**ï¼šéœ€è¦æ¢ç´¢å¤šç§å¯èƒ½æ€§çš„åœºæ™¯

## æŸæœç´¢ï¼ˆBeam Searchï¼‰

### åŸç†è¯´æ˜
æŸæœç´¢æ˜¯ä¸€ç§å¯å‘å¼æœç´¢ç®—æ³•ï¼Œå®ƒåœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ä¿ç•™å¤šä¸ªå€™é€‰åºåˆ—ï¼ˆæŸï¼‰ï¼Œè€Œä¸æ˜¯åªé€‰æ‹©ä¸€ä¸ªæœ€ä½³åºåˆ—ã€‚é€šè¿‡ç»´æŠ¤å¤šæ¡è·¯å¾„ï¼Œå®ƒèƒ½å¤Ÿåœ¨è®¡ç®—æ•ˆç‡å’Œç”Ÿæˆè´¨é‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šç»´æŠ¤å¤šæ¡å€™é€‰è·¯å¾„ â†’ é€‰æ‹©ç´¯ç§¯æ¦‚ç‡æœ€é«˜çš„åºåˆ—

**ç®—æ³•æµç¨‹**ï¼š
1. **åˆå§‹åŒ–**ï¼šä»è¾“å…¥åºåˆ—å¼€å§‹
2. **æ‰©å±•**ï¼šä¸ºæ¯ä¸ªå€™é€‰åºåˆ—ç”Ÿæˆå¤šä¸ªæ‰©å±•
3. **è¯„åˆ†**ï¼šè®¡ç®—æ¯ä¸ªæ–°åºåˆ—çš„ç´¯ç§¯æ¦‚ç‡
4. **ç­›é€‰**ï¼šä¿ç•™åˆ†æ•°æœ€é«˜çš„Nä¸ªå€™é€‰
5. **é‡å¤**ï¼šç»§ç»­æ‰©å±•ç›´åˆ°ç»“æŸæ¡ä»¶

### å…³é”®æ¦‚å¿µ

#### æŸå®½åº¦ï¼ˆBeam Widthï¼‰
- **å®šä¹‰**ï¼šæ¯æ­¥ä¿ç•™çš„å€™é€‰åºåˆ—æ•°é‡
- **æƒè¡¡**ï¼š
  - å®½åº¦=1ï¼šç­‰ä»·äºè´ªå©ªè§£ç 
  - å®½åº¦è¶Šå¤§ï¼šæœç´¢ç©ºé—´è¶Šå¤§ï¼Œè´¨é‡è¶Šé«˜ï¼Œä½†è®¡ç®—æˆæœ¬ä¹Ÿè¶Šå¤§

#### ç´¯ç§¯æ¦‚ç‡
- **è®¡ç®—æ–¹å¼**ï¼šåºåˆ—æ¦‚ç‡ = å„ä¸ªtokenæ¦‚ç‡çš„ä¹˜ç§¯
- **æ•°å€¼ç¨³å®šæ€§**ï¼šé€šå¸¸ä½¿ç”¨å¯¹æ•°æ¦‚ç‡æ±‚å’Œ
- **å…¬å¼**ï¼š`log P(sequence) = Î£ log P(token_i | context)`

### ä»£ç å®ç°
åŸºäºæˆ‘ä»¬å®ç°çš„ `_beam_search` æ–¹æ³•ï¼š

```python
def _beam_search(self, idx: torch.Tensor, max_new_tokens: int, num_beams: int,
                 temperature: float = 1.0, top_k: int = None, stop_id: int = None) -> torch.Tensor:
    """
    æŸæœç´¢ï¼šç»´æŠ¤å¤šä¸ªå€™é€‰åºåˆ—ï¼Œé€‰æ‹©æœ€ä¼˜è·¯å¾„

    Args:
        idx: è¾“å…¥åºåˆ—ï¼Œå½¢çŠ¶ä¸º (batch_size, seq_len)
        max_new_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°é‡
        num_beams: æŸå®½åº¦ï¼Œè¡¨ç¤ºä¿ç•™çš„å€™é€‰è·¯å¾„æ•°é‡
        temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶åˆ†å¸ƒçš„å¹³æ»‘ç¨‹åº¦
        top_k: top-kè¿‡æ»¤å‚æ•°ï¼Œé™åˆ¶å€™é€‰tokenèŒƒå›´
        stop_id: åœæ­¢ç”Ÿæˆçš„token IDï¼Œé‡åˆ°åˆ™åœæ­¢

    Returns:
        ç”Ÿæˆçš„tokenåºåˆ—ï¼Œå½¢çŠ¶ä¸º (batch_size, generated_length)
    """
    # 1. åˆå§‹åŒ–æŸ
    beams = [idx.clone() for _ in range(num_beams)]
    beam_scores = torch.zeros(num_beams, device=idx.device)
    beam_scores[0] = 0.0  # ç¬¬ä¸€ä¸ªå€™é€‰æ˜¯åŸå§‹åºåˆ—
    beam_scores[1:] = float('-inf')  # å…¶ä»–å€™é€‰åˆå§‹åˆ†æ•°ä¸ºè´Ÿæ— ç©·

    # 2. ä¸»å¾ªç¯ï¼šé€æ­¥ç”Ÿæˆtoken
    for step in range(max_new_tokens):
        new_beams = []
        new_scores = []

        # 3. æ‰©å±•æ¯ä¸ªå€™é€‰åºåˆ—
        for beam_idx, beam in enumerate(beams):
            if beam_scores[beam_idx] == float('-inf'):
                continue  # è·³è¿‡æ— æ•ˆå€™é€‰

            # å‰å‘ä¼ æ’­è·å–logits
            output = self(beam)
            logits = output.logits[:, -1, :]

            # åº”ç”¨æ¸©åº¦å’Œtop-k
            if temperature != 1.0:
                logits = logits / temperature
            if top_k is not None:
                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))
                logits[logits < v[:, [-1]]] = -float('Inf')

            # è®¡ç®—å¯¹æ•°æ¦‚ç‡
            log_probs = F.log_softmax(logits, dim=-1)

            # è·å–å‰num_beamsä¸ªå€™é€‰token
            top_log_probs, top_indices = torch.topk(log_probs, k=num_beams, dim=-1)

            # 4. ä¸ºå½“å‰å€™é€‰ç”Ÿæˆå¤šä¸ªæ‰©å±•
            for k in range(num_beams):
                token = top_indices[:, k:k+1]
                log_prob = top_log_probs[:, k]

                new_beam = torch.cat([beam, token], dim=1)
                new_score = beam_scores[beam_idx] + log_prob.item()

                new_beams.append(new_beam)
                new_scores.append(new_score)

        # 5. ç­›é€‰æœ€ä½³å€™é€‰
        if not new_beams:
            break

        # æŒ‰åˆ†æ•°æ’åºï¼Œé€‰æ‹©å‰num_beamsä¸ª
        sorted_indices = sorted(range(len(new_scores)), key=lambda i: new_scores[i], reverse=True)
        beams = [new_beams[i] for i in sorted_indices[:num_beams]]
        beam_scores = [new_scores[i] for i in sorted_indices[:num_beams]]

        # æ£€æŸ¥åœæ­¢æ¡ä»¶
        if stop_id is not None and beams[0][0, -1] == stop_id:
            break

    # 6. è¿”å›æœ€ä½³åºåˆ—
    return beams[0][:, idx.shape[1]:]  # åªè¿”å›ç”Ÿæˆéƒ¨åˆ†
```

### æŸæœç´¢è¿‡ç¨‹ç¤ºä¾‹

å‡è®¾æŸå®½åº¦=3ï¼Œè¾“å…¥="ä»Šå¤©å¤©æ°”"ï¼š

**ç¬¬1æ­¥æ‰©å±•**ï¼š
```
å€™é€‰1: "ä»Šå¤©å¤©æ°”å¾ˆå¥½" (åˆ†æ•°: 0.4)
å€™é€‰2: "ä»Šå¤©å¤©æ°”ä¸é”™" (åˆ†æ•°: 0.3)
å€™é€‰3: "ä»Šå¤©å¤©æ°”çœŸå¥½" (åˆ†æ•°: 0.2)
```

**ç¬¬2æ­¥æ‰©å±•**ï¼ˆæ¯ä¸ªå€™é€‰å†æ‰©å±•3ä¸ªï¼‰ï¼š
```
å€™é€‰1.1: "ä»Šå¤©å¤©æ°”å¾ˆå¥½å•Š" (åˆ†æ•°: 0.4 + 0.1 = 0.5)
å€™é€‰1.2: "ä»Šå¤©å¤©æ°”å¾ˆå¥½ã€‚" (åˆ†æ•°: 0.4 + 0.2 = 0.6) â† ä¿ç•™
å€™é€‰1.3: "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œ" (åˆ†æ•°: 0.4 + 0.05 = 0.45)

å€™é€‰2.1: "ä»Šå¤©å¤©æ°”ä¸é”™å•Š" (åˆ†æ•°: 0.3 + 0.15 = 0.45)
å€™é€‰2.2: "ä»Šå¤©å¤©æ°”ä¸é”™ã€‚" (åˆ†æ•°: 0.3 + 0.1 = 0.4) â† ä¿ç•™
å€™é€‰2.3: "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œ" (åˆ†æ•°: 0.3 + 0.08 = 0.38)

å€™é€‰3.1: "ä»Šå¤©å¤©æ°”çœŸå¥½å•Š" (åˆ†æ•°: 0.2 + 0.12 = 0.32)
å€™é€‰3.2: "ä»Šå¤©å¤©æ°”çœŸå¥½ã€‚" (åˆ†æ•°: 0.2 + 0.25 = 0.45) â† ä¿ç•™
å€™é€‰3.3: "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œ" (åˆ†æ•°: 0.2 + 0.1 = 0.3)
```

**ç­›é€‰ç»“æœ**ï¼ˆä¿ç•™åˆ†æ•°æœ€é«˜çš„3ä¸ªï¼‰ï¼š
```
æœ€ä½³å€™é€‰: "ä»Šå¤©å¤©æ°”å¾ˆå¥½ã€‚" (åˆ†æ•°: 0.6)
æ¬¡ä½³å€™é€‰: "ä»Šå¤©å¤©æ°”ä¸é”™ã€‚" (åˆ†æ•°: 0.4)
ç¬¬ä¸‰å€™é€‰: "ä»Šå¤©å¤©æ°”çœŸå¥½ã€‚" (åˆ†æ•°: 0.45)
```

### ä½¿ç”¨ç¤ºä¾‹
```python
# åŸºæœ¬æŸæœç´¢
output = model.generate_super(
    input_ids,
    do_sample=False,        # ä¸ä½¿ç”¨é‡‡æ ·
    num_beams=3,           # æŸå®½åº¦ä¸º3
    temperature=1.0,       # æ ‡å‡†æ¸©åº¦
    max_new_tokens=100
)

# å¸¦top-kçš„æŸæœç´¢
output = model.generate_super(
    input_ids,
    do_sample=False,
    num_beams=5,           # æ›´å¤§çš„æŸå®½åº¦
    temperature=0.8,       # ç¨å¾®é™ä½æ¸©åº¦
    top_k=50,             # é™åˆ¶å€™é€‰èŒƒå›´
    max_new_tokens=100
)
```

### ä¼˜ç¼ºç‚¹åˆ†æ

**ä¼˜ç‚¹**ï¼š
- âœ… **è´¨é‡è¾ƒé«˜**ï¼šæ¯”è´ªå©ªè§£ç è´¨é‡æ›´å¥½
- âœ… **ç¡®å®šæ€§**ï¼šç»“æœç›¸å¯¹ç¨³å®šï¼ˆç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡ºï¼‰
- âœ… **å¹³è¡¡æ€§å¥½**ï¼šåœ¨è´¨é‡å’Œæ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡
- âœ… **é¿å…æ˜æ˜¾é”™è¯¯**ï¼šä¸å®¹æ˜“é€‰æ‹©æ˜æ˜¾ä¸åˆé€‚çš„token

**ç¼ºç‚¹**ï¼š
- âŒ **è®¡ç®—å¼€é”€å¤§**ï¼šéœ€è¦ç»´æŠ¤å¤šä¸ªå€™é€‰åºåˆ—
- âŒ **å†…å­˜å ç”¨é«˜**ï¼šå­˜å‚¨å¤šä¸ªå€™é€‰åºåˆ—å’Œåˆ†æ•°
- âŒ **ä»å¯èƒ½å±€éƒ¨æœ€ä¼˜**ï¼šè™½ç„¶æ¯”è´ªå©ªå¥½ï¼Œä½†ä»å¯èƒ½é”™è¿‡å…¨å±€æœ€ä¼˜
- âŒ **å¤šæ ·æ€§æœ‰é™**ï¼šä»ç„¶åå‘é«˜æ¦‚ç‡è·¯å¾„ï¼Œåˆ›é€ æ€§ä¸å¦‚é‡‡æ ·

### æŸå®½åº¦é€‰æ‹©å»ºè®®

| æŸå®½åº¦ | é€‚ç”¨åœºæ™¯ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|--------|----------|------|------|
| 1-2 | å®æ—¶åº”ç”¨ã€è®¡ç®—èµ„æºæœ‰é™ | é€Ÿåº¦å¿«ã€èµ„æºå ç”¨å°‘ | è´¨é‡ç›¸å¯¹è¾ƒä½ |
| 3-5 | ä¸€èˆ¬å¯¹è¯ã€æ–‡æœ¬ç”Ÿæˆ | è´¨é‡è¾ƒå¥½ã€é€Ÿåº¦é€‚ä¸­ | èµ„æºå ç”¨ä¸­ç­‰ |
| 6-10 | é«˜è´¨é‡ç”Ÿæˆã€ç¿»è¯‘ | è´¨é‡å¾ˆé«˜ | è®¡ç®—å¼€é”€å¤§ |
| 10+ | ä¸“ä¸šåº”ç”¨ã€ç ”ç©¶ | æœ€é«˜è´¨é‡ | å¼€é”€å¾ˆå¤§ |

### ä½¿ç”¨åœºæ™¯
- **æœºå™¨ç¿»è¯‘**ï¼šéœ€è¦å‡†ç¡®æ€§å’Œæµç•…æ€§çš„å¹³è¡¡
- **æ–‡æœ¬æ‘˜è¦**ï¼šç”Ÿæˆè¿è´¯çš„æ‘˜è¦å†…å®¹
- **å¯¹è¯ç³»ç»Ÿ**ï¼šç”Ÿæˆæœ‰é€»è¾‘çš„å›å¤
- **ä»£ç ç”Ÿæˆ**ï¼šéœ€è¦è¯­æ³•æ­£ç¡®å’Œé€»è¾‘åˆç†
- **é•¿æ–‡æœ¬ç”Ÿæˆ**ï¼šå¦‚æ–‡ç« å†™ä½œã€æŠ¥å‘Šç”Ÿæˆ

## è¾…åŠ©æ¨¡å‹æŠ•æœºè§£ç ï¼ˆAssisted Decodingï¼‰

### åŸç†è¯´æ˜
æŠ•æœºè§£ç æ˜¯ä¸€ç§**ç”¨å°æ¨¡å‹åŠ é€Ÿå¤§æ¨¡å‹æ¨ç†**çš„æŠ€æœ¯ã€‚å®ƒé€šè¿‡"è‰ç¨¿-éªŒè¯"çš„æ–¹å¼ï¼Œè®©å°å…ˆç”Ÿæˆå€™é€‰tokenï¼Œç„¶åå¤§å®¶æ¨¡å‹å¿«é€ŸéªŒè¯ï¼Œå‡å°‘å¤§æ¨¡å‹çš„å‰å‘ä¼ æ’­æ¬¡æ•°ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šå°æ¨¡å‹æŠ•æœºç”Ÿæˆ â†’ å¤§æ¨¡å‹æ‰¹é‡éªŒè¯ â†’ å‡å°‘å¤§æ¨¡å‹è®¡ç®—è´Ÿæ‹…

### å·¥ä½œæµç¨‹

#### 1. è‰ç¨¿ç”Ÿæˆé˜¶æ®µ
```
è¾“å…¥: "ä»Šå¤©å¤©æ°”"
å°æ¨¡å‹å¿«é€Ÿç”Ÿæˆè‰ç¨¿: "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥"
```

#### 2. éªŒè¯é˜¶æ®µ
å¤§æ¨¡å‹ä¸€æ¬¡æ€§éªŒè¯æ•´ä¸ªè‰ç¨¿åºåˆ—ï¼š
- âœ… æ¥å—çš„tokenï¼š"ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œ"
- âŒ æ‹’ç»çš„tokenï¼šä»"é€‚åˆ"å¼€å§‹æ‹’ç»
- ğŸ”§ å¤§æ¨¡å‹é‡æ–°ç”Ÿæˆï¼š"é€‚åˆåœ¨å®¶ä¼‘æ¯"

#### 3. æœ€ç»ˆç»“æœ
```
è¾“å‡º: "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆåœ¨å®¶ä¼‘æ¯"
```

### å…³é”®ä¼˜åŠ¿

**é€Ÿåº¦æå‡**ï¼š
- å°æ¨¡å‹æ¨ç†å¿« â†’ ç”Ÿæˆå¤šä¸ªå€™é€‰token
- å¤§æ¨¡å‹æ‰¹é‡éªŒè¯ â†’ ä¸€æ¬¡å¤„ç†å¤šä¸ªtoken
- å‡å°‘90%+çš„å¤§æ¨¡å‹å‰å‘ä¼ æ’­

**è´¨é‡ä¿è¯**ï¼š
- å¤§æ¨¡å‹æœ‰æœ€ç»ˆå¦å†³æƒ
- åªæœ‰å¤§æ¨¡å‹è®¤å¯çš„tokenæ‰ä¼šè¢«ä¿ç•™
- ä¸ä¼šé™ä½ç”Ÿæˆè´¨é‡

### å…·ä½“ä¾‹å­å¯¹æ¯”

**ä¼ ç»Ÿæ–¹å¼**ï¼ˆå¤§æ¨¡å‹é€ä¸ªç”Ÿæˆï¼‰ï¼š
```
ç¬¬1æ­¥: å¤§æ¨¡å‹ â†’ "ä»Šå¤©"
ç¬¬2æ­¥: å¤§æ¨¡å‹ â†’ "ä»Šå¤©å¤©æ°”"
ç¬¬3æ­¥: å¤§æ¨¡å‹ â†’ "ä»Šå¤©å¤©æ°”å¾ˆ"
ç¬¬4æ­¥: å¤§æ¨¡å‹ â†’ "ä»Šå¤©å¤©æ°”å¾ˆå¥½"
ç¬¬5æ­¥: å¤§æ¨¡å‹ â†’ "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œ"
ç¬¬6æ­¥: å¤§æ¨¡å‹ â†’ "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆ"
... (æ¯æ­¥éƒ½éœ€è¦å¤§æ¨¡å‹å‰å‘ä¼ æ’­)
```

**æŠ•æœºè§£ç **ï¼š
```
ç¬¬1æ­¥: å°æ¨¡å‹å¿«é€Ÿè‰ç¨¿ â†’ "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥"
ç¬¬2æ­¥: å¤§æ¨¡å‹æ‰¹é‡éªŒè¯ â†’ æ¥å—"ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œ"ï¼Œæ‹’ç»"é€‚åˆå‡ºé—¨æ•£æ­¥"
ç¬¬3æ­¥: å¤§æ¨¡å‹é‡æ–°ç”Ÿæˆ â†’ "é€‚åˆåœ¨å®¶ä¼‘æ¯"
```

è¿™æ ·åŸæœ¬éœ€è¦6æ¬¡å¤§æ¨¡å‹æ¨ç†çš„è¿‡ç¨‹ï¼Œç°åœ¨åªéœ€è¦2æ¬¡ï¼

### æŠ€æœ¯å®ç°è¦ç‚¹

#### 1. è‰ç¨¿é•¿åº¦æ§åˆ¶
- **è‰ç¨¿ä¸å®œè¿‡é•¿**ï¼šé€šå¸¸2-10ä¸ªtoken
- **æ¥å—ç‡å¹³è¡¡**ï¼šå¤ªé•¿æ¥å—ç‡ä½ï¼Œå¤ªçŸ­åŠ é€Ÿæ•ˆæœä¸æ˜æ˜¾
- **åŠ¨æ€è°ƒæ•´**ï¼šæ ¹æ®æ¥å—ç‡è°ƒæ•´è‰ç¨¿é•¿åº¦

#### 2. éªŒè¯æœºåˆ¶
```python
# ä¼ªä»£ç 
def assisted_decoding(input_ids, assistant_model, main_model):
    # å°æ¨¡å‹ç”Ÿæˆè‰ç¨¿
    draft_tokens = assistant_model.generate_draft(input_ids, max_draft_len=5)

    # å¤§æ¨¡å‹éªŒè¯
    accepted_count = main_model.verify_draft(input_ids, draft_tokens)

    # æ„å»ºæœ€ç»ˆç»“æœ
    if accepted_count == len(draft_tokens):
        return draft_tokens  # å…¨éƒ¨æ¥å—
    else:
        # éƒ¨åˆ†æ¥å—ï¼Œå¤§æ¨¡å‹é‡æ–°ç”Ÿæˆå‰©ä½™éƒ¨åˆ†
        accepted_part = draft_tokens[:accepted_count]
        remaining_part = main_model.generate_remaining(input_ids + accepted_part)
        return accepted_part + remaining_part
```

### æ€»ç»“
æŠ•æœºè§£ç æœ¬è´¨ä¸Šæ˜¯ç”¨**è®¡ç®—èµ„æºæ¢æ—¶é—´**ï¼Œé€šè¿‡å°æ¨¡å‹çš„"æŠ•æœº"æ¥å‡å°‘å¤§æ¨¡å‹çš„è®¡ç®—è´Ÿæ‹…ã€‚å®ƒæ˜¯ä¸€ç§èªæ˜çš„å·¥ç¨‹ä¼˜åŒ–ï¼Œåœ¨ä¸ç‰ºç‰²è´¨é‡çš„å‰æä¸‹æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ã€‚